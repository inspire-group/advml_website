<!DOCTYPE html>
<html lang="en">

<head>
	<meta charset="utf-8"/>
	<title>PAC-learning in the presence of evasion adversaries</title>
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	
	<!-- RSS feed -->
	<link rel="alternate" type="application/rss+xml" title="Adversarial ML @ Princeton" href="http://adversarial-learning.princeton.edu//feed.xml">
	
    <!-- Customized Bootstrap + Font Awesome + Solarized -->
    <link href="/css/style.css" rel="stylesheet" media="screen">

	<!-- Favicon -->
	<link rel="shortcut icon" href="/images/favicon.png"/>	

	<!-- Typekit -->
	<script>
	  (function(d) {
		var config = {
		  kitId: 'xeu8jut',
		  scriptTimeout: 3000
		},
		h=d.documentElement,t=setTimeout(function(){h.className=h.className.replace(/\bwf-loading\b/g,"")+" wf-inactive";},config.scriptTimeout),tk=d.createElement("script"),f=false,s=d.getElementsByTagName("script")[0],a;h.className+=" wf-loading";tk.src='//use.typekit.net/'+config.kitId+'.js';tk.async=true;tk.onload=tk.onreadystatechange=function(){a=this.readyState;if(f||a&&a!="complete"&&a!="loaded")return;f=true;clearTimeout(t);try{Typekit.load(config)}catch(e){}};s.parentNode.insertBefore(tk,s)
	  })(document);
	</script>
		
	<!-- Google Analytics -->	
	<script>
		(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

		ga('create', 'UA-26244371-2', 'bedford.io');
		ga('send', 'pageview');

	</script>
	
	<!-- jQuery -->
	<script src="/js/jquery.min.js"></script>
	
	<!-- Bootstrap -->
	<script src="/js/transition.js"></script>
	<script src="/js/collapse.js"></script>

</head>

<body>
	
	<div id="header">
		<nav class="navbar navbar-default navbar-static-top" role="navigation">	 
			<div class="container">	
				<div class="navbar-header">
					<button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar-collapse-element" aria-expanded="false">
						<span class="sr-only">Toggle navigation</span>
						<span class="icon-bar"></span>
						<span class="icon-bar"></span>
						<span class="icon-bar"></span>
					</button>
										
					<object class="logo navbar-brand" data="/images/logo.svg" type="image/svg+xml"></object>
					<a class="navbar-brand" href="/">Adversarial ML @ Princeton</a>
					
				</div>
				<div class="collapse navbar-collapse" id="navbar-collapse-element">
					<ul class="nav navbar-nav navbar-right">
						
						<li>
						
						<a href="/blog/">blog</a>
						</li>
						
						<li class="active">
						
						<a href="/research/">research</a>
						</li>
<!-- 						
						<li>
						
						<a href="/projects/">projects</a></li>	 -->  
						
						<li>
						
						<a href="/team/">team</a></li>	  	  
					</ul>
				</div>
			</div>
		</nav>	
	</div>
	
	<div class="container">	
		
	<div class="row">
	<div class="col-md-12">
		<div class="media">
			
			<img class="pull-left pad-right media-object" src="/images/papers/cullina-adversarial-pac.png">
			
			<div class="media-body titlebox">
				<div class="title media-heading">
					PAC-learning in the presence of evasion adversaries
				</div>
				<p>
				<div class="smallhead">
					Cullina D., Bhagoji A.N., Mittal P.,
					<i>Advances in Neural Information Processing Systems</i>
					<i>2018</i>
				</div>
			</div>
		</div>
	</div>
</div>

<div class="bigspacer"></div>

<div class="row">
	<div class="col-md-3">
		<div class="bigspacer"></div>
		<div class="glyphbox note">
			
			<div class="smallhead">
				PDF
			</div>
			<div class="pad-left note">
				<div class="smallspacer"></div>
				<i class="fa fa-file-text-o fa-fw"></i>
				<a class="off" href="/pdfs/papers/cullina-adversarial-pac.pdf">cullina-adversarial-pac.pdf</a>
			</div>
			<div class="bigspacer"></div>
			
			
			
			<div class="smallhead">
				ArXiv
			</div>
			<div class="pad-left note">
				<div class="smallspacer"></div>
				<i class="fa fa-external-link fa-fw"></i>
				<a class="off" href="https://arxiv.org/abs/1806.01471">1806.01471</a>
			</div>
			<div class="bigspacer"></div>
			
			
		</div>
	</div>
	<div class="col-md-8">
		<div class="post">
			<h1>Abstract</h1>

<p>The existence of evasion attacks during the test phase of machine learning algorithms represents a significant challenge to both their deployment and understanding. These attacks can be carried out by adding imperceptible perturbations to inputs to generate adversarial examples and finding effective defenses and detectors has proven to be difficult. In this paper, we step away from the attack-defense arms race and seek to understand the limits of what can be learned in the presence of an evasion adversary. In particular, we extend the Probably Approximately Correct (PAC)-learning framework to account for the presence of an adversary. We first define corrupted hypothesis classes which arise from standard binary hypothesis classes in the presence of an evasion adversary and derive the Vapnik-Chervonenkis (VC)-dimension for these, denoted as the adversarial VC-dimension. We then show that sample complexity upper bounds from the Fundamental Theorem of Statistical learning can be extended to the case of evasion adversaries, where the sample complexity is controlled by the adversarial VC-dimension. We then explicitly derive the adversarial VC-dimension for halfspace classifiers in the presence of a sample-wise norm-constrained adversary of the type commonly studied for evasion attacks and show that it is the same as the standard VC-dimension, closing an open question. Finally, we prove that the adversarial VC-dimension can be either larger or smaller than the standard VC-dimension depending on the hypothesis class and adversary, making it an interesting object of study in its own right.</p>

		</div>
	</div>
	<div class="col-md-1"></div>
</div>

	
	</div>
	
	<div id="footer"><span style="display:none">foo</span></div>
		
</body>
</html>

